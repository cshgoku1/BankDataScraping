name: Daily Scrape Banking Data

on:
  schedule:
    - cron: '0 8 * * *'  # Daily at 8 AM UTC
  workflow_dispatch:     # Manual run button in GitHub UI

jobs:
  run-scraper:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repo
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

        # Install Chromium and required libraries
        sudo apt-get update
        sudo apt-get install -y wget unzip xvfb libxi6 libgconf-2-4 \
          libappindicator1 libnss3 libxss1 libasound2 libatk1.0-0 \
          libatk-bridge2.0-0 libgbm1 libgtk-3-0 chromium-browser

        # Optional chromedriver check (usually not needed for uc)
        if [ ! -f /usr/bin/chromedriver ]; then
          sudo cp /usr/lib/chromium-browser/chromedriver /usr/bin/chromedriver
        fi

    - name: Run daily scraper
      env:
        DISPLAY: ":99"
      run: |
        python dailyscraper.py

    - name: Commit scraped CSVs
      run: |
        git config --global user.name "github-actions"
        git config --global user.email "github-actions@github.com"
        git add data/
        git commit -m "Auto update scraped data - $(date)"
        git push
