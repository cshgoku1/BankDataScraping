name: Daily Scrape Banking Data

on:
  schedule:
    - cron: '0 8 * * *'  # Daily at 8 AM UTC
  workflow_dispatch:     # Manual run button in GitHub UI

jobs:
  run-scraper:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repo
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        sudo apt-get update
        sudo apt-get install -y chromium-browser chromium-chromedriver
        if [! -f /usr/bin/chromedriver ]; then
        sudo cp /usr/lib/chromium-browser/chromedriver /usr/bin/chromedriver
        fi

        sudo apt-get install -y fonts-liberation libappindicator3-1 xdg-utils

    - name: Run daily scraper
      env:
        DISPLAY: ":99"
      run: |
        python daily_scraper.py

    - name: Commit scraped CSVs
      run: |
        git config --global user.name "github-actions"
        git config --global user.email "github-actions@github.com"
        git add data/
        git commit -m " Auto update scraped data - $(date)"
        git push
